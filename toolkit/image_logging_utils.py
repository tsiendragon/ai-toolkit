"""
å›¾åƒæ—¥å¿—è®°å½•å·¥å…·å‡½æ•°
ç”¨äºåœ¨ TensorBoard ä¸­è®°å½•è®­ç»ƒå›¾åƒå’Œæ§åˆ¶å›¾åƒ

Created by Tsien at 2025-08-18
"""

import torch
import torchvision
from torch.utils.tensorboard import SummaryWriter
from typing import Optional, Union, List, TYPE_CHECKING
import numpy as np
from PIL import Image

if TYPE_CHECKING:
    from toolkit.data_transfer_object.data_loader import DataLoaderBatchDTO


def tensor_to_pil(tensor: torch.Tensor) -> Image.Image:
    """
    å°†å¼ é‡è½¬æ¢ä¸º PIL å›¾åƒ

    Args:
        tensor: å½¢çŠ¶ä¸º [C, H, W] æˆ– [H, W, C] çš„å›¾åƒå¼ é‡ï¼Œå€¼èŒƒå›´ [0, 1] æˆ– [-1, 1]

    Returns:
        PIL Image å¯¹è±¡
    """
    # ç¡®ä¿å¼ é‡åœ¨ CPU ä¸Š
    if tensor.is_cuda:
        tensor = tensor.cpu()

    # å¤„ç†ä¸åŒçš„è¾“å…¥æ ¼å¼
    if tensor.dim() == 4:
        # å¦‚æœæ˜¯æ‰¹æ¬¡ï¼Œå–ç¬¬ä¸€ä¸ª
        tensor = tensor[0]

    if tensor.dim() == 3:
        # [C, H, W] æ ¼å¼
        if tensor.shape[0] == 3 or tensor.shape[0] == 1:
            # é€šé“åœ¨ç¬¬ä¸€ç»´
            pass
        elif tensor.shape[2] == 3 or tensor.shape[2] == 1:
            # [H, W, C] æ ¼å¼ï¼Œè½¬æ¢ä¸º [C, H, W]
            tensor = tensor.permute(2, 0, 1)
        else:
            raise ValueError(f"Unsupported tensor shape: {tensor.shape}")

    # å½’ä¸€åŒ–åˆ° [0, 1] èŒƒå›´
    if tensor.min() < 0:
        # å‡è®¾èŒƒå›´æ˜¯ [-1, 1]
        tensor = (tensor + 1.0) / 2.0

    # ç¡®ä¿åœ¨ [0, 1] èŒƒå›´å†…
    tensor = torch.clamp(tensor, 0, 1)

    # è½¬æ¢ä¸º PIL å›¾åƒ
    if tensor.shape[0] == 1:
        # ç°åº¦å›¾åƒ
        tensor = tensor.squeeze(0)
        image = Image.fromarray((tensor * 255).numpy().astype(np.uint8), mode='L')
    else:
        # RGB å›¾åƒ
        image = torchvision.transforms.ToPILImage()(tensor)

    return image


def create_image_grid(
    training_images: torch.Tensor,
    control_images: Optional[torch.Tensor] = None,
    max_images: int = 8,
    grid_cols: int = 4
) -> torch.Tensor:
    """
    åˆ›å»ºè®­ç»ƒå›¾åƒå’Œæ§åˆ¶å›¾åƒçš„ç½‘æ ¼æ˜¾ç¤º

    Args:
        training_images: è®­ç»ƒå›¾åƒå¼ é‡ [B, C, H, W]
        control_images: æ§åˆ¶å›¾åƒå¼ é‡ [B, C, H, W]ï¼Œå¯é€‰
        max_images: æœ€å¤§æ˜¾ç¤ºå›¾åƒæ•°é‡
        grid_cols: ç½‘æ ¼åˆ—æ•°

    Returns:
        ç½‘æ ¼å›¾åƒå¼ é‡
    """
    batch_size = training_images.shape[0]
    num_images = min(batch_size, max_images)

    images_to_show = []

    for i in range(num_images):
        # æ·»åŠ è®­ç»ƒå›¾åƒ
        train_img = training_images[i]
        images_to_show.append(train_img)

        # æ·»åŠ å¯¹åº”çš„æ§åˆ¶å›¾åƒï¼ˆå¦‚æœæœ‰ï¼‰
        if control_images is not None and i < control_images.shape[0]:
            control_img = control_images[i]
            images_to_show.append(control_img)

    # åˆ›å»ºç½‘æ ¼
    if len(images_to_show) > 0:
        grid = torchvision.utils.make_grid(
            images_to_show,
            nrow=grid_cols,
            normalize=True,
            value_range=(-1, 1) if training_images.min() < 0 else (0, 1),
            padding=2,
            pad_value=1.0
        )
        return grid
    else:
        # è¿”å›ç©ºç™½å›¾åƒ
        return torch.zeros(3, 256, 256)


def log_training_images(
    writer: SummaryWriter,
    batch: 'DataLoaderBatchDTO',
    step: int,
    max_images: int = 8,
    tag_prefix: str = "training"
) -> None:
    """
    åœ¨ TensorBoard ä¸­è®°å½•è®­ç»ƒå›¾åƒå’Œæ§åˆ¶å›¾åƒ

    é‡è¦ï¼šæ­¤å‡½æ•°åº”è¯¥åªåœ¨ä¸»è¿›ç¨‹(rank-0)ä¸­è°ƒç”¨ï¼Œä»¥é¿å…åˆ†å¸ƒå¼è®­ç»ƒä¸­çš„å†²çª

    Args:
        writer: TensorBoard SummaryWriter
        batch: è®­ç»ƒæ‰¹æ¬¡æ•°æ®
        step: å½“å‰è®­ç»ƒæ­¥æ•°
        max_images: æœ€å¤§è®°å½•å›¾åƒæ•°é‡
        tag_prefix: æ ‡ç­¾å‰ç¼€
    """
    try:
        # å®‰å…¨æ£€æŸ¥ï¼šé¿å…éä¸»è¿›ç¨‹è®°å½•æ—¥å¿— - by Tsien at 2025-08-18
        import os
        local_rank = int(os.environ.get('LOCAL_RANK', 0))
        if local_rank != 0:
            return  # éä¸»è¿›ç¨‹ç›´æ¥è¿”å›ï¼Œä¸è®°å½•æ—¥å¿—

        # å®‰å…¨æ£€æŸ¥æ‰¹æ¬¡å¯¹è±¡
        if batch is None:
            print(f"âš ï¸ [IMAGE_LOG] æ‰¹æ¬¡å¯¹è±¡ä¸ºç©º")
            return

        # è·å–è®­ç»ƒå›¾åƒ - æ”¯æŒlatentç¼“å­˜æ¨¡å¼ - by Tsien at 2025-01-27
        training_images = None

        # æ–¹å¼1ï¼šç›´æ¥ä»tensorè·å–ï¼ˆéç¼“å­˜æ¨¡å¼ï¼‰
        if hasattr(batch, 'tensor') and batch.tensor is not None:
            training_images = batch.tensor
            print(f"âœ… [IMAGE_LOG] ä½¿ç”¨ç›´æ¥å›¾åƒtensorè¿›è¡Œè®°å½•")

        # æ–¹å¼2ï¼šä»latentç¼“å­˜æ¨¡å¼æŒ‰éœ€åŠ è½½ï¼ˆæ–°åŠŸèƒ½ï¼‰
        elif hasattr(batch, 'latents') and batch.latents is not None:
            print(f"ğŸ”„ [IMAGE_LOG] æ£€æµ‹åˆ°latentç¼“å­˜æ¨¡å¼ï¼Œå°è¯•æŒ‰éœ€åŠ è½½åŸå§‹å›¾åƒ...")

            # å°è¯•ä½¿ç”¨æ–°çš„æŒ‰éœ€åŠ è½½åŠŸèƒ½
            if hasattr(batch, 'get_images_for_tensorboard'):
                try:
                    training_images = batch.get_images_for_tensorboard(max_images=max_images)
                    if training_images is not None:
                        print(f"âœ… [IMAGE_LOG] æˆåŠŸä»latentç¼“å­˜æ¨¡å¼åŠ è½½ {training_images.shape[0]} å¼ å›¾åƒç”¨äºTensorBoard")
                    else:
                        print(f"âš ï¸ [IMAGE_LOG] æŒ‰éœ€åŠ è½½å›¾åƒå¤±è´¥ï¼Œè·³è¿‡å›¾åƒè®°å½•")
                        return
                except Exception as e:
                    print(f"âš ï¸ [IMAGE_LOG] æŒ‰éœ€åŠ è½½å›¾åƒæ—¶å‡ºé”™: {e}")
                    return
            else:
                print(f"âš ï¸ [IMAGE_LOG] å½“å‰ç‰ˆæœ¬ä¸æ”¯æŒlatentç¼“å­˜æ¨¡å¼ä¸‹çš„å›¾åƒè®°å½•")
                print(f"âš ï¸ [IMAGE_LOG] å¦‚éœ€å¯ç”¨å›¾åƒè®°å½•ï¼Œè¯·åœ¨é…ç½®ä¸­è®¾ç½® cache_latents_to_disk: false")
                return

        # æ–¹å¼3ï¼šæ— æ³•è·å–å›¾åƒ
        else:
            # æ£€æŸ¥batchçš„æ‰€æœ‰å±æ€§ï¼Œç”¨äºè°ƒè¯•
            available_attrs = []
            for attr in dir(batch):
                if not attr.startswith('_'):
                    try:
                        value = getattr(batch, attr, None)
                        if value is not None and not callable(value):
                            if isinstance(value, torch.Tensor):
                                available_attrs.append(f"{attr}(tensor:{list(value.shape)})")
                            else:
                                available_attrs.append(f"{attr}({type(value).__name__})")
                    except:
                        pass
            # print(f"âš ï¸ [IMAGE_LOG] æ‰¹æ¬¡ä¸­æ²¡æœ‰å¯ç”¨çš„è®­ç»ƒå›¾åƒã€‚å¯ç”¨å±æ€§: {available_attrs}")
            return

        if training_images is None:
            print(f"âš ï¸ [IMAGE_LOG] è®­ç»ƒå›¾åƒä¸ºç©º")
            return

        # è·å–æ§åˆ¶å›¾åƒï¼ˆå¦‚æœæœ‰ï¼‰
        control_images = None
        if hasattr(batch, 'control_tensor') and batch.control_tensor is not None:
            control_images = batch.control_tensor

        # ç¡®ä¿å›¾åƒåœ¨åˆç†èŒƒå›´å†…
        num_images = min(training_images.shape[0], max_images)

        # è®°å½•è®­ç»ƒå›¾åƒ
        if training_images is not None:
            train_grid = create_image_grid(
                training_images[:num_images],
                None,  # å•ç‹¬æ˜¾ç¤ºè®­ç»ƒå›¾åƒ
                max_images=num_images,
                grid_cols=4
            )
            writer.add_image(f"{tag_prefix}/training_images", train_grid, step)

        # è®°å½•æ§åˆ¶å›¾åƒï¼ˆå¦‚æœæœ‰ï¼‰
        if control_images is not None:
            control_grid = create_image_grid(
                control_images[:num_images],
                None,  # å•ç‹¬æ˜¾ç¤ºæ§åˆ¶å›¾åƒ
                max_images=num_images,
                grid_cols=4
            )
            writer.add_image(f"{tag_prefix}/control_images", control_grid, step)

            # åˆ›å»ºå¹¶è®°å½•ç»„åˆè§†å›¾ï¼ˆè®­ç»ƒå›¾åƒå’Œæ§åˆ¶å›¾åƒå¹¶æ’ï¼‰
            combined_grid = create_image_grid(
                training_images[:num_images],
                control_images[:num_images],
                max_images=num_images,
                grid_cols=4  # æ¯è¡Œ4å¯¹å›¾åƒ
            )
            writer.add_image(f"{tag_prefix}/training_control_pairs", combined_grid, step)

        print(f"ğŸ“¸ [IMAGE_LOG] å·²è®°å½• {num_images} å¯¹è®­ç»ƒå›¾åƒåˆ° TensorBoard (step {step})")

    except Exception as e:
        print(f"âŒ [IMAGE_LOG] è®°å½•å›¾åƒæ—¶å‡ºé”™: {e}")


def log_individual_images(
    writer: SummaryWriter,
    batch: 'DataLoaderBatchDTO',
    step: int,
    max_images: int = 8
) -> None:
    """
    è®°å½•å•ä¸ªå›¾åƒå¯¹ï¼ˆä¾¿äºè¯¦ç»†æŸ¥çœ‹ï¼‰

    é‡è¦ï¼šæ­¤å‡½æ•°åº”è¯¥åªåœ¨ä¸»è¿›ç¨‹(rank-0)ä¸­è°ƒç”¨ï¼Œä»¥é¿å…åˆ†å¸ƒå¼è®­ç»ƒä¸­çš„å†²çª

    Args:
        writer: TensorBoard SummaryWriter
        batch: è®­ç»ƒæ‰¹æ¬¡æ•°æ®
        step: å½“å‰è®­ç»ƒæ­¥æ•°
        max_images: æœ€å¤§è®°å½•å›¾åƒæ•°é‡
    """
    try:
        # å®‰å…¨æ£€æŸ¥ï¼šé¿å…éä¸»è¿›ç¨‹è®°å½•æ—¥å¿— - by Tsien at 2025-08-18
        import os
        local_rank = int(os.environ.get('LOCAL_RANK', 0))
        if local_rank != 0:
            return  # éä¸»è¿›ç¨‹ç›´æ¥è¿”å›ï¼Œä¸è®°å½•æ—¥å¿—

        # å®‰å…¨æ£€æŸ¥æ‰¹æ¬¡å¯¹è±¡ - æ”¯æŒlatentç¼“å­˜æ¨¡å¼ - by Tsien at 2025-01-27
        if batch is None:
            return

        training_images = None

        # æ”¯æŒlatentç¼“å­˜æ¨¡å¼çš„å›¾åƒè·å–
        if hasattr(batch, 'tensor') and batch.tensor is not None:
            training_images = batch.tensor
        elif hasattr(batch, 'latents') and batch.latents is not None and hasattr(batch, 'get_images_for_tensorboard'):
            try:
                training_images = batch.get_images_for_tensorboard(max_images=max_images)
            except Exception as e:
                print(f"âš ï¸ [IMAGE_LOG] ä¸ªåˆ«å›¾åƒè®°å½•æ—¶æŒ‰éœ€åŠ è½½å¤±è´¥: {e}")
                return

        control_images = None
        if hasattr(batch, 'control_tensor') and batch.control_tensor is not None:
            control_images = batch.control_tensor

        if training_images is None:
            return

        num_images = min(training_images.shape[0], max_images)

        for i in range(num_images):
            # è®°å½•å•ä¸ªè®­ç»ƒå›¾åƒ
            train_img = training_images[i:i+1]  # ä¿æŒæ‰¹æ¬¡ç»´åº¦
            train_grid = torchvision.utils.make_grid(
                train_img,
                normalize=True,
                value_range=(-1, 1) if train_img.min() < 0 else (0, 1)
            )
            writer.add_image(f"individual/training_image_{i}", train_grid, step)

            # è®°å½•å¯¹åº”çš„æ§åˆ¶å›¾åƒï¼ˆå¦‚æœæœ‰ï¼‰
            if control_images is not None and i < control_images.shape[0]:
                control_img = control_images[i:i+1]  # ä¿æŒæ‰¹æ¬¡ç»´åº¦
                control_grid = torchvision.utils.make_grid(
                    control_img,
                    normalize=True,
                    value_range=(-1, 1) if control_img.min() < 0 else (0, 1)
                )
                writer.add_image(f"individual/control_image_{i}", control_grid, step)

    except Exception as e:
        print(f"âŒ [IMAGE_LOG] è®°å½•å•ä¸ªå›¾åƒæ—¶å‡ºé”™: {e}")


def log_sample_images(
    writer: SummaryWriter,
    images: List[Image.Image],
    prompts: List[str],
    step: int,
    max_images: int = 8,
    tag_prefix: str = "samples",
    control_images: Optional[List[Image.Image]] = None
) -> None:
    """
    åœ¨ TensorBoard ä¸­è®°å½•è®­ç»ƒè¿‡ç¨‹ä¸­ç”Ÿæˆçš„æ ·æœ¬å›¾åƒ

    é‡è¦ï¼šæ­¤å‡½æ•°åº”è¯¥åªåœ¨ä¸»è¿›ç¨‹(rank-0)ä¸­è°ƒç”¨ï¼Œä»¥é¿å…åˆ†å¸ƒå¼è®­ç»ƒä¸­çš„å†²çª

    Args:
        writer: TensorBoard SummaryWriter
        images: ç”Ÿæˆçš„ PIL å›¾åƒåˆ—è¡¨
        prompts: å¯¹åº”çš„æç¤ºè¯åˆ—è¡¨
        step: å½“å‰è®­ç»ƒæ­¥æ•°
        max_images: æœ€å¤§è®°å½•å›¾åƒæ•°é‡
        tag_prefix: æ ‡ç­¾å‰ç¼€
        control_images: æ§åˆ¶å›¾åƒåˆ—è¡¨ï¼ˆåŸå›¾ï¼‰ï¼Œç”¨äºå¯¹æ¯”æ˜¾ç¤º
    """
    try:
        # å®‰å…¨æ£€æŸ¥ï¼šé¿å…éä¸»è¿›ç¨‹è®°å½•æ—¥å¿—
        import os
        local_rank = int(os.environ.get('LOCAL_RANK', 0))
        if local_rank != 0:
            return  # éä¸»è¿›ç¨‹ç›´æ¥è¿”å›ï¼Œä¸è®°å½•æ—¥å¿—

        if not images or len(images) == 0:
            print(f"âš ï¸ [SAMPLE_LOG] æ²¡æœ‰æ ·æœ¬å›¾åƒéœ€è¦è®°å½•")
            return

        # é™åˆ¶è®°å½•çš„å›¾åƒæ•°é‡
        num_images = min(len(images), max_images)
        images_to_log = images[:num_images]
        prompts_to_log = prompts[:num_images] if prompts else [f"sample_{i}" for i in range(num_images)]

        # å°† PIL å›¾åƒè½¬æ¢ä¸ºå¼ é‡
        image_tensors = []
        for i, pil_img in enumerate(images_to_log):
            try:
                # ç¡®ä¿å›¾åƒæ˜¯ RGB æ¨¡å¼
                if pil_img.mode != 'RGB':
                    pil_img = pil_img.convert('RGB')

                # è½¬æ¢ä¸ºå¼ é‡ [C, H, W]ï¼Œå€¼èŒƒå›´ [0, 1]
                img_array = np.array(pil_img).astype(np.float32) / 255.0
                img_tensor = torch.from_numpy(img_array).permute(2, 0, 1)  # [H, W, C] -> [C, H, W]
                image_tensors.append(img_tensor)
            except Exception as e:
                print(f"âš ï¸ [SAMPLE_LOG] è½¬æ¢å›¾åƒ {i} æ—¶å‡ºé”™: {e}")
                continue

        if not image_tensors:
            print(f"âš ï¸ [SAMPLE_LOG] æ²¡æœ‰æœ‰æ•ˆçš„å›¾åƒå¼ é‡")
            return

        # åˆ›å»ºç½‘æ ¼æ˜¾ç¤º
        if len(image_tensors) > 1:
            # å¤šä¸ªå›¾åƒï¼Œåˆ›å»ºç½‘æ ¼
            grid_cols = min(4, len(image_tensors))  # æœ€å¤š4åˆ—
            grid = torchvision.utils.make_grid(
                image_tensors,
                nrow=grid_cols,
                normalize=False,  # å·²ç»å½’ä¸€åŒ–åˆ° [0,1]
                padding=2,
                pad_value=1.0
            )
            writer.add_image(f"{tag_prefix}/generated_samples", grid, step)
        else:
            # å•ä¸ªå›¾åƒ
            writer.add_image(f"{tag_prefix}/generated_sample", image_tensors[0], step)

        # å¦‚æœæœ‰æ§åˆ¶å›¾åƒï¼Œåˆ›å»ºå¯¹æ¯”æ‹¼æ¥æ˜¾ç¤º
        if control_images and len(control_images) > 0:
            try:
                comparison_tensors = []
                control_tensors = []

                # è½¬æ¢æ§åˆ¶å›¾åƒä¸ºå¼ é‡
                for i, ctrl_img in enumerate(control_images[:num_images]):
                    try:
                        if ctrl_img.mode != 'RGB':
                            ctrl_img = ctrl_img.convert('RGB')
                        # è°ƒæ•´æ§åˆ¶å›¾åƒå°ºå¯¸ä¸ç”Ÿæˆå›¾åƒä¸€è‡´
                        if i < len(images_to_log):
                            target_size = images_to_log[i].size
                            ctrl_img = ctrl_img.resize(target_size, Image.Resampling.LANCZOS)

                        ctrl_array = np.array(ctrl_img).astype(np.float32) / 255.0
                        ctrl_tensor = torch.from_numpy(ctrl_array).permute(2, 0, 1)
                        control_tensors.append(ctrl_tensor)
                    except Exception as e:
                        print(f"âš ï¸ [SAMPLE_LOG] è½¬æ¢æ§åˆ¶å›¾åƒ {i} æ—¶å‡ºé”™: {e}")
                        continue

                # åˆ›å»ºå¯¹æ¯”æ‹¼æ¥å›¾åƒï¼ˆåŸå›¾-ç¼–è¾‘å›¾å¹¶æ’ï¼‰
                for i, (gen_tensor, ctrl_tensor) in enumerate(zip(image_tensors, control_tensors)):
                    if i >= len(prompts_to_log):
                        break
                    try:
                        # æ‹¼æ¥å›¾åƒï¼šå·¦è¾¹åŸå›¾ï¼Œå³è¾¹ç¼–è¾‘å›¾
                        comparison_tensor = torch.cat([ctrl_tensor, gen_tensor], dim=2)  # æ°´å¹³æ‹¼æ¥
                        comparison_tensors.append(comparison_tensor)
                    except Exception as e:
                        print(f"âš ï¸ [SAMPLE_LOG] æ‹¼æ¥å›¾åƒ {i} æ—¶å‡ºé”™: {e}")
                        continue

                # è®°å½•å¯¹æ¯”ç½‘æ ¼
                if comparison_tensors:
                    if len(comparison_tensors) > 1:
                        comparison_grid = torchvision.utils.make_grid(
                            comparison_tensors,
                            nrow=min(2, len(comparison_tensors)),  # æ¯è¡Œæœ€å¤š2ä¸ªå¯¹æ¯”å›¾
                            normalize=False,
                            padding=4,
                            pad_value=1.0
                        )
                        writer.add_image(f"{tag_prefix}/before_after_comparison", comparison_grid, step)
                    else:
                        writer.add_image(f"{tag_prefix}/before_after_comparison", comparison_tensors[0], step)

                # ç§»é™¤å•ä¸ªå¯¹æ¯”å›¾åƒè®°å½• - åªä¿ç•™ç½‘æ ¼è§†å›¾ - by Tsien at 2025-01-27
                # è¿™æ ·å¯ä»¥é¿å…é‡å¤è®°å½•ç›¸åŒçš„å›¾åƒå†…å®¹

                print(f"ğŸ“¸ [SAMPLE_LOG] å·²è®°å½• {len(comparison_tensors)} å¼ å¯¹æ¯”å›¾åƒåˆ° TensorBoard")

            except Exception as e:
                print(f"âš ï¸ [SAMPLE_LOG] åˆ›å»ºå¯¹æ¯”å›¾åƒæ—¶å‡ºé”™: {e}")

        # è®°å½•å•ä¸ªç”Ÿæˆå›¾åƒï¼ˆä¾¿äºè¯¦ç»†æŸ¥çœ‹ï¼‰
        for i, (img_tensor, prompt) in enumerate(zip(image_tensors, prompts_to_log)):
            # æ¸…ç†æç¤ºè¯ä½œä¸ºæ ‡ç­¾ï¼ˆç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼‰
            clean_prompt = prompt.replace("/", "_").replace("\\", "_")[:50]  # é™åˆ¶é•¿åº¦
            writer.add_image(f"{tag_prefix}/individual/sample_{i}_{clean_prompt}", img_tensor, step)

        print(f"ğŸ“¸ [SAMPLE_LOG] å·²è®°å½• {len(image_tensors)} å¼ æ ·æœ¬å›¾åƒåˆ° TensorBoard (step {step})")

    except Exception as e:
        print(f"âŒ [SAMPLE_LOG] è®°å½•æ ·æœ¬å›¾åƒæ—¶å‡ºé”™: {e}")


def should_log_images(step: int, log_images_every: int, log_images: bool = True) -> bool:
    """
    åˆ¤æ–­æ˜¯å¦åº”è¯¥åœ¨å½“å‰æ­¥éª¤è®°å½•å›¾åƒ

    Args:
        step: å½“å‰è®­ç»ƒæ­¥æ•°
        log_images_every: å›¾åƒè®°å½•é—´éš”
        log_images: æ˜¯å¦å¯ç”¨å›¾åƒè®°å½•

    Returns:
        bool: æ˜¯å¦åº”è¯¥è®°å½•å›¾åƒ
    """
    if not log_images:
        return False

    if log_images_every <= 0:
        return False

    return step % log_images_every == 0 and step > 0


def should_log_samples(step: int, sample_every: int, log_samples: bool = True) -> bool:
    """
    åˆ¤æ–­æ˜¯å¦åº”è¯¥åœ¨å½“å‰æ­¥éª¤è®°å½•æ ·æœ¬å›¾åƒ

    Args:
        step: å½“å‰è®­ç»ƒæ­¥æ•°
        sample_every: æ ·æœ¬ç”Ÿæˆé—´éš”ï¼ˆå½“ç”Ÿæˆæ ·æœ¬æ—¶æ‰è®°å½•ï¼‰
        log_samples: æ˜¯å¦å¯ç”¨æ ·æœ¬è®°å½•

    Returns:
        bool: æ˜¯å¦åº”è¯¥è®°å½•æ ·æœ¬
    """
    if not log_samples:
        return False

    if sample_every <= 0:
        return False

    return step % sample_every == 0 and step > 0
